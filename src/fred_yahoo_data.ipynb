{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fredapi as fred\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Set the API key\n",
    "\n",
    "FRED_API_KEY = os.getenv('FRED_API_KEY')\n",
    "\n",
    "# Create a FRED API object\n",
    "fred_api = fred.Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "# Get the release dates for all releases\n",
    "release_dates = fred_api.get_series_all_releases('UNRATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# 현재 작업 디렉토리 설정\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# 데이터 파일 경로 설정\n",
    "data_path = os.path.join('../data', 'nowcast-model-variables.xlsx')\n",
    "\n",
    "variables = pd.read_excel(data_path, engine='openpyxl', sheet_name='variables')\n",
    "releases = pd.read_excel(data_path, engine='openpyxl', sheet_name='releases')\n",
    "\n",
    "variables.to_csv('../data/nowcast-variables.csv')\n",
    "releases.to_csv('../data/nowcast-releases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>fullname</th>\n",
       "      <th>dispgroup</th>\n",
       "      <th>disporder</th>\n",
       "      <th>release</th>\n",
       "      <th>units</th>\n",
       "      <th>st</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>hist_source</th>\n",
       "      <th>hist_source_key</th>\n",
       "      <th>hist_source_freq</th>\n",
       "      <th>hist_source_transform</th>\n",
       "      <th>nc_dfm_input</th>\n",
       "      <th>nc_method</th>\n",
       "      <th>nc_input_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mpce</td>\n",
       "      <td>PCE</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>3</td>\n",
       "      <td>BEA.PI</td>\n",
       "      <td>billions of 2012 $</td>\n",
       "      <td>dlog</td>\n",
       "      <td>apchg</td>\n",
       "      <td>base</td>\n",
       "      <td>fred</td>\n",
       "      <td>PCEC96</td>\n",
       "      <td>m</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>po</td>\n",
       "      <td>Personal Outlays</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>1</td>\n",
       "      <td>BEA.PI</td>\n",
       "      <td>billions of 2012 $</td>\n",
       "      <td>dlog</td>\n",
       "      <td>apchg</td>\n",
       "      <td>none</td>\n",
       "      <td>fred</td>\n",
       "      <td>A068RC1</td>\n",
       "      <td>m</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ps</td>\n",
       "      <td>Personal Savings</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>1</td>\n",
       "      <td>BEA.PI</td>\n",
       "      <td>billions of 2012 $</td>\n",
       "      <td>dlog</td>\n",
       "      <td>apchg</td>\n",
       "      <td>none</td>\n",
       "      <td>fred</td>\n",
       "      <td>PMSAVE</td>\n",
       "      <td>m</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psr</td>\n",
       "      <td>Personal Savings Rate</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>1</td>\n",
       "      <td>BEA.PI</td>\n",
       "      <td>billions of 2012 $</td>\n",
       "      <td>base</td>\n",
       "      <td>base</td>\n",
       "      <td>none</td>\n",
       "      <td>fred</td>\n",
       "      <td>PSAVERT</td>\n",
       "      <td>m</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>calc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pi</td>\n",
       "      <td>Personal Income</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>1</td>\n",
       "      <td>BEA.PI</td>\n",
       "      <td>billions of 2012 $</td>\n",
       "      <td>dlog</td>\n",
       "      <td>apchg</td>\n",
       "      <td>none</td>\n",
       "      <td>fred</td>\n",
       "      <td>RPI</td>\n",
       "      <td>m</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>moo</td>\n",
       "      <td>Agricultural Commodities (DBA)</td>\n",
       "      <td>Stocks_and_Commodities</td>\n",
       "      <td>2</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>index</td>\n",
       "      <td>dlog</td>\n",
       "      <td>pchg</td>\n",
       "      <td>base</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>DBA</td>\n",
       "      <td>d</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>metals</td>\n",
       "      <td>Metal Commodities (DBB)</td>\n",
       "      <td>Stocks_and_Commodities</td>\n",
       "      <td>2</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>index</td>\n",
       "      <td>dlog</td>\n",
       "      <td>pchg</td>\n",
       "      <td>base</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>DBB</td>\n",
       "      <td>d</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>oil</td>\n",
       "      <td>Crude Oil Price (West Texas Intermediate)</td>\n",
       "      <td>Stocks_and_Commodities</td>\n",
       "      <td>2</td>\n",
       "      <td>EIA.SPOT</td>\n",
       "      <td>$ per barrel</td>\n",
       "      <td>base</td>\n",
       "      <td>base</td>\n",
       "      <td>none</td>\n",
       "      <td>fred</td>\n",
       "      <td>DCOILWTICO</td>\n",
       "      <td>d</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>usd</td>\n",
       "      <td>U.S. Dollar Index</td>\n",
       "      <td>Stocks_and_Commodities</td>\n",
       "      <td>1</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>index</td>\n",
       "      <td>base</td>\n",
       "      <td>base</td>\n",
       "      <td>none</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>UUP</td>\n",
       "      <td>d</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>spdw</td>\n",
       "      <td>Ex-US Equities (SPDW)</td>\n",
       "      <td>Stocks_and_Commodities</td>\n",
       "      <td>2</td>\n",
       "      <td>YHOO</td>\n",
       "      <td>index</td>\n",
       "      <td>dlog</td>\n",
       "      <td>pchg</td>\n",
       "      <td>base</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>SPDW</td>\n",
       "      <td>d</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dfm.m</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   varname                                   fullname               dispgroup  \\\n",
       "0     mpce                                        PCE                Consumer   \n",
       "1       po                           Personal Outlays                Consumer   \n",
       "2       ps                           Personal Savings                Consumer   \n",
       "3      psr                      Personal Savings Rate                Consumer   \n",
       "4       pi                            Personal Income                Consumer   \n",
       "..     ...                                        ...                     ...   \n",
       "90     moo             Agricultural Commodities (DBA)  Stocks_and_Commodities   \n",
       "91  metals                    Metal Commodities (DBB)  Stocks_and_Commodities   \n",
       "92     oil  Crude Oil Price (West Texas Intermediate)  Stocks_and_Commodities   \n",
       "93     usd                          U.S. Dollar Index  Stocks_and_Commodities   \n",
       "94    spdw                      Ex-US Equities (SPDW)  Stocks_and_Commodities   \n",
       "\n",
       "    disporder   release                units    st     d1    d2 hist_source  \\\n",
       "0           3    BEA.PI  billions of 2012 $   dlog  apchg  base        fred   \n",
       "1           1    BEA.PI  billions of 2012 $   dlog  apchg  none        fred   \n",
       "2           1    BEA.PI  billions of 2012 $   dlog  apchg  none        fred   \n",
       "3           1    BEA.PI  billions of 2012 $   base   base  none        fred   \n",
       "4           1    BEA.PI  billions of 2012 $   dlog  apchg  none        fred   \n",
       "..        ...       ...                  ...   ...    ...   ...         ...   \n",
       "90          2      YHOO                index  dlog   pchg  base       yahoo   \n",
       "91          2      YHOO                index  dlog   pchg  base       yahoo   \n",
       "92          2  EIA.SPOT         $ per barrel  base   base  none        fred   \n",
       "93          1      YHOO                index  base   base  none       yahoo   \n",
       "94          2      YHOO                index  dlog   pchg  base       yahoo   \n",
       "\n",
       "   hist_source_key hist_source_freq hist_source_transform  nc_dfm_input  \\\n",
       "0           PCEC96                m                  none           1.0   \n",
       "1          A068RC1                m                  none           0.0   \n",
       "2           PMSAVE                m                  none           0.0   \n",
       "3          PSAVERT                m                  none           1.0   \n",
       "4              RPI                m                  none           0.0   \n",
       "..             ...              ...                   ...           ...   \n",
       "90             DBA                d                  none           1.0   \n",
       "91             DBB                d                  none           1.0   \n",
       "92      DCOILWTICO                d                  none           1.0   \n",
       "93             UUP                d                  none           0.0   \n",
       "94            SPDW                d                  none           1.0   \n",
       "\n",
       "   nc_method nc_input_reason  \n",
       "0      dfm.m             NaN  \n",
       "1      dfm.m             NaN  \n",
       "2      dfm.m             NaN  \n",
       "3       calc             NaN  \n",
       "4      dfm.m             NaN  \n",
       "..       ...             ...  \n",
       "90     dfm.m             NaN  \n",
       "91     dfm.m             NaN  \n",
       "92     dfm.m             NaN  \n",
       "93     dfm.m             NaN  \n",
       "94     dfm.m             NaN  \n",
       "\n",
       "[95 rows x 16 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007-01-01    4.6\n",
       "2007-02-01    4.5\n",
       "2007-03-01    4.4\n",
       "2007-04-01    4.5\n",
       "2007-05-01    4.4\n",
       "             ... \n",
       "2024-10-01    4.1\n",
       "2024-11-01    4.2\n",
       "2024-12-01    4.1\n",
       "2025-01-01    4.0\n",
       "2025-02-01    4.1\n",
       "Name: UNRATE, Length: 218, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "데이터 수집 및 전처리를 위한 함수들\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_fred_data(fred_api, series_id, start_date='2007-01-01', end_date=None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    FRED API를 통해 데이터를 가져오는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fred_api : fredapi.Fred\n",
    "        FRED API 객체\n",
    "    series_id : str\n",
    "        FRED 시리즈 ID\n",
    "    start_date : str\n",
    "        시작 날짜 (YYYY-MM-DD 형식)\n",
    "    end_date : str, optional\n",
    "        종료 날짜 (YYYY-MM-DD 형식)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series\n",
    "        수집된 시계열 데이터\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = fred_api.get_series(series_id, observation_start=start_date, observation_end=end_date)\n",
    "        data = pd.Series(data, index=pd.to_datetime(data.index))\n",
    "        data.name = series_id\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"FRED 데이터 수집 실패 - {series_id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_yahoo_data(ticker, start_date='2007-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    Yahoo Finance를 통해 데이터를 가져오는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ticker : str\n",
    "        Yahoo Finance 티커 심볼\n",
    "    start_date : str\n",
    "        시작 날짜 (YYYY-MM-DD 형식)\n",
    "    end_date : str, optional\n",
    "        종료 날짜 (YYYY-MM-DD 형식)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series\n",
    "        수집된 종가 데이터\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 데이터 다운로드\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        \n",
    "        # 종가만 선택하고 시리즈로 변환\n",
    "        data[f'{ticker}'] = data['Close']\n",
    "        \n",
    "        # Ticker 제외 나머지는 모두 Drop\n",
    "        data = data[f'{ticker}']\n",
    "        \n",
    "        # 인덱스 이름을 'Date'로 설정\n",
    "        data.index.name = 'Date'\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Yahoo Finance 데이터 수집 실패 - {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 데이터 수집 실행\n",
    "start_date = '2007-01-01'\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# 결과 저장\n",
    "output_dir = '../data/collected'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "get_fred_data(fred_api, 'UNRATE', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_to_daily(data, start_date, end_date):\n",
    "    \"\"\"\n",
    "    데이터를 일별로 리샘플링하는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.Series\n",
    "        원본 데이터\n",
    "    start_date : str\n",
    "        시작 날짜 (YYYY-MM-DD 형식)\n",
    "    end_date : str\n",
    "        종료 날짜 (YYYY-MM-DD 형식)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series\n",
    "        일별 리샘플링된 데이터\n",
    "    \"\"\"\n",
    "    # 날짜 인덱스 생성\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # 데이터 리샘플링\n",
    "    resampled = data.reindex(date_range)\n",
    "    \n",
    "    # 결측치 처리 (전진 채우기 후 역진 채우기)\n",
    "    resampled = resampled.fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    return resampled\n",
    "\n",
    "def collect_data(variables_df, fred_api, start_date='2007-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    FRED와 Yahoo Finance에서 데이터를 수집하고 일별로 리샘플링하는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    variables_df : pd.DataFrame\n",
    "        변수 정보가 담긴 데이터프레임\n",
    "    fred_api : fredapi.Fred\n",
    "        FRED API 객체\n",
    "    start_date : str\n",
    "        시작 날짜 (YYYY-MM-DD 형식)\n",
    "    end_date : str, optional\n",
    "        종료 날짜 (YYYY-MM-DD 형식)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        일별 리샘플링된 모든 데이터\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # 데이터 수집을 위한 딕셔너리\n",
    "    collected_data = {}\n",
    "    \n",
    "    # 진행 상황 표시를 위한 tqdm 설정\n",
    "    for _, row in tqdm(variables_df.iterrows(), total=len(variables_df), desc=\"데이터 수집 중\"):\n",
    "        try:\n",
    "            varname = row['varname']\n",
    "            source = row['hist_source']\n",
    "            source_key = row['hist_source_key']\n",
    "            \n",
    "            # 데이터 소스별 수집\n",
    "            if source == 'fred':\n",
    "                data = get_fred_data(fred_api, source_key, start_date, end_date)\n",
    "            elif source == 'yahoo':\n",
    "                data = get_yahoo_data(source_key, start_date, end_date)\n",
    "            else:\n",
    "                logger.warning(f\"알 수 없는 데이터 소스: {source} - {varname}\")\n",
    "                continue\n",
    "            \n",
    "            # 데이터 검증 및 리샘플링\n",
    "            if data is not None and not data.empty:\n",
    "                resampled_data = resample_to_daily(data, start_date, end_date)\n",
    "                collected_data[varname] = resampled_data\n",
    "            else:\n",
    "                logger.warning(f\"데이터 수집 실패 또는 빈 데이터: {varname}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"데이터 수집 중 오류 발생 - {varname}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # 데이터프레임 생성\n",
    "    if not collected_data:\n",
    "        logger.error(\"수집된 데이터가 없습니다.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 모든 데이터를 하나의 데이터프레임으로 병합\n",
    "    df = pd.DataFrame(collected_data)\n",
    "    \n",
    "    # 데이터 검증\n",
    "    logger.info(f\"수집된 데이터 크기: {df.shape}\")\n",
    "    logger.info(f\"결측치 개수:\\n{df.isnull().sum()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 데이터 수집 실행\n",
    "start_date = '2007-01-01'\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# 데이터 수집\n",
    "all_data = collect_data(variables, fred_api, start_date, end_date)\n",
    "\n",
    "# 결과 저장\n",
    "if not all_data.empty:\n",
    "    output_dir = '../data/collected'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file = f'{output_dir}/collected_data_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "    all_data.to_csv(output_file)\n",
    "    logger.info(f\"데이터가 {output_file}에 저장되었습니다.\")\n",
    "    \n",
    "    # 데이터 확인\n",
    "    print(\"\\n수집된 데이터 정보:\")\n",
    "    print(all_data.info())\n",
    "    print(\"\\n결측치 개수:\")\n",
    "    print(all_data.isnull().sum())\n",
    "    \n",
    "    # 데이터 예시 출력\n",
    "    print(\"\\n데이터 예시 (처음 5행):\")\n",
    "    print(all_data.head())\n",
    "else:\n",
    "    logger.error(\"데이터 수집 실패\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = 'e3e226dad48bd746bbe401b9e1d4de13'\n",
    "BASE_URL = 'https://api.stlouisfed.org/fred'\n",
    "\n",
    "source_key = 'CPIAUCSL'\n",
    "\n",
    "source_metadata = []\n",
    "unit_metadata = []\n",
    "\n",
    "release_url = f'{BASE_URL}/series/release'\n",
    "release_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "release_response = requests.get(release_url, params=release_params).json()\n",
    "release_id = release_response['releases'][0]['id']  # or .get('id')\n",
    "\n",
    "obs_url = f'{BASE_URL}/series/observations'\n",
    "obs_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "obs_r = requests.get(obs_url, params=obs_params).json()\n",
    "obs_unit = obs_r['units']\n",
    "obs_data = obs_r['observations']\n",
    "\n",
    "source_metadata.append(source_key)\n",
    "source_metadata.append(obs_unit)\n",
    "\n",
    "rel_url = f'{BASE_URL}/release/dates'\n",
    "rel_params = {'api_key': API_KEY, 'file_type': 'json', 'release_id': release_id}\n",
    "rel_data = requests.get(rel_url, params=rel_params).json()['release_dates']\n",
    "\n",
    "obs_df = pd.DataFrame(obs_data)\n",
    "obs_df['date'] = pd.to_datetime(obs_df['date'])\n",
    "obs_df['target_month'] = obs_df['date'].dt.to_period('M').astype(str)\n",
    "obs_df['base'] = (obs_df['date'] + pd.DateOffset(months=1)).dt.to_period('M').astype(str)\n",
    "obs_df[f'{source_key}'] = obs_df['value'].astype(float)\n",
    "obs_df = obs_df[['target_month', f'{source_key}', 'base']]\n",
    "\n",
    "rel_df = pd.DataFrame(rel_data)\n",
    "rel_df['release_date'] = pd.to_datetime(rel_df['date'])\n",
    "rel_df['base'] = rel_df['release_date'].dt.to_period('M').astype(str)\n",
    "rel_df = rel_df[['release_date', 'base']]\n",
    "\n",
    "final_df = obs_df.merge(rel_df, on='base', how='left').drop(columns=['base'])\n",
    "final_df.dropna(inplace=True)\n",
    "\n",
    "final_df = final_df.set_index('release_date').resample('D').asfreq()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_month</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949-03-24</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>23.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-12</th>\n",
       "      <td>2025-02</td>\n",
       "      <td>319.775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             target_month  CPIAUCSL\n",
       "release_date                       \n",
       "1949-03-24        1949-02    23.910\n",
       "1949-03-25            NaN       NaN\n",
       "1949-03-26            NaN       NaN\n",
       "1949-03-27            NaN       NaN\n",
       "1949-03-28            NaN       NaN\n",
       "...                   ...       ...\n",
       "2025-03-08            NaN       NaN\n",
       "2025-03-09            NaN       NaN\n",
       "2025-03-10            NaN       NaN\n",
       "2025-03-11            NaN       NaN\n",
       "2025-03-12        2025-02   319.775\n",
       "\n",
       "[27748 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = 'e3e226dad48bd746bbe401b9e1d4de13'\n",
    "BASE_URL = 'https://api.stlouisfed.org/fred'\n",
    "\n",
    "source_key = 'CPIAUCSL'\n",
    "\n",
    "# 메타데이터 수집\n",
    "meta_url = f'{BASE_URL}/series'\n",
    "meta_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "meta_r = requests.get(meta_url, params=meta_params).json()['seriess']\n",
    "meta_df = pd.DataFrame(meta_r)\n",
    "\n",
    "# release id\n",
    "release_url = f'{BASE_URL}/series/release'\n",
    "release_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "release_id = requests.get(release_url, params=release_params).json()['releases'][0]['id']\n",
    "\n",
    "# obs\n",
    "obs_url = f'{BASE_URL}/series/observations'\n",
    "obs_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "obs_data = requests.get(obs_url, params=obs_params).json()['observations']\n",
    "\n",
    "# release dates\n",
    "rel_url = f'{BASE_URL}/release/dates'\n",
    "rel_params = {'api_key': API_KEY, 'file_type': 'json', 'release_id': release_id}\n",
    "rel_data = requests.get(rel_url, params=rel_params).json()['release_dates']\n",
    "\n",
    "# obs_df\n",
    "obs_df = pd.DataFrame(obs_data)\n",
    "obs_df['date'] = pd.to_datetime(obs_df['date'])\n",
    "obs_df['target_month'] = obs_df['date'].dt.to_period('M').astype(str)\n",
    "obs_df['base'] = (obs_df['date'] + pd.DateOffset(months=1)).dt.to_period('M').astype(str)\n",
    "obs_df[source_key] = obs_df['value'].astype(float)\n",
    "obs_df = obs_df[['target_month', source_key, 'base']]\n",
    "\n",
    "# release_df\n",
    "rel_df = pd.DataFrame(rel_data)\n",
    "rel_df['release_date'] = pd.to_datetime(rel_df['date'])\n",
    "rel_df['base'] = rel_df['release_date'].dt.to_period('M').astype(str)\n",
    "rel_df = rel_df[['release_date', 'base']]\n",
    "\n",
    "# merge\n",
    "final_df = obs_df.merge(rel_df, on='base', how='inner').drop(columns=['base'])\n",
    "final_df = final_df.set_index('release_date').resample('D').asfreq()\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = 'e3e226dad48bd746bbe401b9e1d4de13'\n",
    "BASE_URL = 'https://api.stlouisfed.org/fred'\n",
    "\n",
    "source_keys = pd.read_csv('../data/nowcast-variables.csv')\n",
    "\n",
    "# hist_source가 fred인 경우\n",
    "fred_keys = source_keys[source_keys['hist_source'] == 'fred']['hist_source_key']\n",
    "\n",
    "# hist_source가 yahoo인 경우\n",
    "yf_tickers = source_keys[source_keys['hist_source'] == 'yahoo']['hist_source_key']\n",
    "\n",
    "# yf_tickers의 종가를 yfinacne로 다운로드하여 병합\n",
    "import yfinance as yf\n",
    "\n",
    "data_dict = {}\n",
    "for ticker in yf_tickers:\n",
    "    data = yf.download(ticker, start='2000-01-01', end='2024-12-31')\n",
    "    data = data['Close']\n",
    "    data.name = ticker\n",
    "    data_dict[ticker] = data\n",
    "\n",
    "market_df = pd.concat(data_dict.values(), axis=1)\n",
    "market_df.columns = data_dict.keys()\n",
    "market_df.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PCEC96...\n",
      "Processing A068RC1...\n",
      "Processing PMSAVE...\n",
      "Processing PSAVERT...\n",
      "Processing RPI...\n",
      "Processing DSPIC96...\n",
      "Processing TOTCI...\n",
      "Processing RELACBW027SBOG...\n",
      "Processing DRSFRMACBS...\n",
      "Processing DRCCLACBS...\n",
      "Processing DRBLACBS...\n",
      "Processing GDPC1...\n",
      "Processing PCECC96...\n",
      "Processing DGDSRX1Q020SBEA...\n",
      "Processing PCDGCC96...\n",
      "Processing DMOTRX1Q020SBEA...\n",
      "Processing DFDHRX1Q020SBEA...\n",
      "Processing DREQRX1Q020SBEA...\n",
      "Processing DODGRX1Q020SBEA...\n",
      "Processing PCNDGC96...\n",
      "Processing DFXARX1Q020SBEA...\n",
      "Processing DCLORX1Q020SBEA...\n",
      "Processing DGOERX1Q020SBEA...\n",
      "Processing DONGRX1Q020SBEA...\n",
      "Processing PCESVC96...\n",
      "Processing DHUTRX1Q020SBEA...\n",
      "Processing DHLCRX1Q020SBEA...\n",
      "Processing DTRSRX1Q020SBEA...\n",
      "Processing DRCARX1Q020SBEA...\n",
      "Processing DFSARX1Q020SBEA...\n",
      "Processing DIFSRX1Q020SBEA...\n",
      "Processing DOTSRX1Q020SBEA...\n",
      "Processing DNPIRX1Q020SBEA...\n",
      "Processing GPDIC1...\n",
      "Processing PNFIC1...\n",
      "Processing B009RX1Q020SBEA...\n",
      "Processing Y033RX1Q020SBEA...\n",
      "Processing Y001RX1Q020SBEA...\n",
      "Processing PRFIC1...\n",
      "Processing CBIC1...\n",
      "Processing NETEXC...\n",
      "Processing EXPGSC1...\n",
      "Processing A253RX1Q020SBEA...\n",
      "Processing A646RX1Q020SBEA...\n",
      "Processing IMPGSC1...\n",
      "Processing A255RX1Q020SBEA...\n",
      "Processing B656RX1Q020SBEA...\n",
      "Processing GCEC1...\n",
      "Processing FGCEC1...\n",
      "Processing SLCEC1...\n",
      "Processing CSUSHPISA...\n",
      "Processing SPCS20RSA...\n",
      "Processing HOUST...\n",
      "Processing HSN1F...\n",
      "Processing PERMIT...\n",
      "Processing USAUCSFRCONDOSMSAMID...\n",
      "skip USAUCSFRCONDOSMSAMID: No metadata available\n",
      "Processing PCEPI...\n",
      "skip PCEPI: No metadata available\n",
      "Processing CPIAUCSL...\n",
      "skip CPIAUCSL: No metadata available\n",
      "Processing PPIACO...\n",
      "skip PPIACO: No metadata available\n",
      "Processing UNRATE...\n",
      "skip UNRATE: No metadata available\n",
      "Processing PAYEMS...\n",
      "skip PAYEMS: No metadata available\n",
      "Processing JTSJOL...\n",
      "skip JTSJOL: No metadata available\n",
      "Processing LMJVTTUVUSM647S...\n",
      "skip LMJVTTUVUSM647S: No metadata available\n",
      "Processing CES0500000003...\n",
      "skip CES0500000003: No metadata available\n",
      "Processing STLFSI3...\n",
      "skip STLFSI3: No metadata available\n",
      "Processing FRBKCLMCILA...\n",
      "skip FRBKCLMCILA: No metadata available\n",
      "Processing CIVPART...\n",
      "skip CIVPART: No metadata available\n",
      "Processing INDPRO...\n",
      "skip INDPRO: No metadata available\n",
      "Processing IPFPNSS...\n",
      "skip IPFPNSS: No metadata available\n",
      "Processing IPCONGD...\n",
      "skip IPCONGD: No metadata available\n",
      "Processing IPFUELS...\n",
      "skip IPFUELS: No metadata available\n",
      "Processing DGORDER...\n",
      "skip DGORDER: No metadata available\n",
      "Processing ACOGNO...\n",
      "skip ACOGNO: No metadata available\n",
      "Processing TTLCONS...\n",
      "skip TTLCONS: No metadata available\n",
      "Processing ISRATIO...\n",
      "skip ISRATIO: No metadata available\n",
      "Processing TCU...\n",
      "skip TCU: No metadata available\n",
      "Processing EFFR...\n",
      "skip EFFR: No metadata available\n",
      "Processing MORTGAGE30US...\n",
      "skip MORTGAGE30US: No metadata available\n",
      "Processing DAAA...\n",
      "skip DAAA: No metadata available\n",
      "Processing DBAA...\n",
      "skip DBAA: No metadata available\n",
      "Processing TOTALSA...\n",
      "skip TOTALSA: No metadata available\n",
      "Processing RSAFS...\n",
      "skip RSAFS: No metadata available\n",
      "Processing CSCICP03USM665S...\n",
      "skip CSCICP03USM665S: No metadata available\n",
      "Processing CEFDISA066MSFRBNY...\n",
      "skip CEFDISA066MSFRBNY: No metadata available\n",
      "Processing BACTSAMFRBDAL...\n",
      "skip BACTSAMFRBDAL: No metadata available\n",
      "Processing CEFDFSA066MSFRBPHI...\n",
      "skip CEFDFSA066MSFRBPHI: No metadata available\n",
      "Processing CBBTCUSD...\n",
      "skip CBBTCUSD: No metadata available\n",
      "Processing DCOILWTICO...\n",
      "skip DCOILWTICO: No metadata available\n",
      "메타데이터 df shape: (55, 15)\n",
      "merged_df shape: (28339, 55)\n",
      "        id realtime_start realtime_end  \\\n",
      "0   PCEC96     2025-03-19   2025-03-19   \n",
      "1  A068RC1     2025-03-19   2025-03-19   \n",
      "2   PMSAVE     2025-03-17   2025-03-17   \n",
      "3  PSAVERT     2025-03-18   2025-03-18   \n",
      "4      RPI     2025-03-19   2025-03-19   \n",
      "\n",
      "                                    title observation_start observation_end  \\\n",
      "0  Real Personal Consumption Expenditures        2007-01-01      2025-01-01   \n",
      "1                        Personal outlays        1959-01-01      2025-01-01   \n",
      "2                         Personal Saving        1959-01-01      2025-01-01   \n",
      "3                    Personal Saving Rate        1959-01-01      2025-01-01   \n",
      "4                    Real Personal Income        1959-01-01      2025-01-01   \n",
      "\n",
      "  frequency frequency_short                             units  \\\n",
      "0   Monthly               M  Billions of Chained 2017 Dollars   \n",
      "1   Monthly               M               Billions of Dollars   \n",
      "2   Monthly               M               Billions of Dollars   \n",
      "3   Monthly               M                           Percent   \n",
      "4   Monthly               M  Billions of Chained 2017 Dollars   \n",
      "\n",
      "           units_short              seasonal_adjustment  \\\n",
      "0  Bil. of Chn. 2017 $  Seasonally Adjusted Annual Rate   \n",
      "1            Bil. of $  Seasonally Adjusted Annual Rate   \n",
      "2            Bil. of $  Seasonally Adjusted Annual Rate   \n",
      "3                    %  Seasonally Adjusted Annual Rate   \n",
      "4  Bil. of Chn. 2017 $  Seasonally Adjusted Annual Rate   \n",
      "\n",
      "  seasonal_adjustment_short            last_updated  popularity  \\\n",
      "0                      SAAR  2025-02-28 07:44:25-06          74   \n",
      "1                      SAAR  2025-02-28 07:45:12-06          18   \n",
      "2                      SAAR  2025-02-28 07:45:27-06          66   \n",
      "3                      SAAR  2025-02-28 07:45:28-06          84   \n",
      "4                      SAAR  2025-02-28 07:44:30-06          58   \n",
      "\n",
      "                                               notes  \n",
      "0  BEA Account Code: DPCERX\\nA Guide to the Natio...  \n",
      "1  BEA Account Code: A068RC\\nA Guide to the Natio...  \n",
      "2  BEA Account Code: A071RC\\nA Guide to the Natio...  \n",
      "3  BEA Account Code: A072RC\\nPersonal saving as a...  \n",
      "4  Calculated by the Federal Reserve Bank of St. ...  \n",
      "             PCEC96 A068RC1 PMSAVE PSAVERT  RPI DSPIC96 TOTCI RELACBW027SBOG  \\\n",
      "release_date                                                                   \n",
      "1947-08-17      NaN     NaN    NaN     NaN  NaN     NaN   NaN            NaN   \n",
      "1947-08-18      NaN     NaN    NaN     NaN  NaN     NaN   NaN            NaN   \n",
      "1947-08-19      NaN     NaN    NaN     NaN  NaN     NaN   NaN            NaN   \n",
      "1947-08-20      NaN     NaN    NaN     NaN  NaN     NaN   NaN            NaN   \n",
      "1947-08-21      NaN     NaN    NaN     NaN  NaN     NaN   NaN            NaN   \n",
      "\n",
      "             DRSFRMACBS DRCCLACBS  ... A255RX1Q020SBEA B656RX1Q020SBEA  \\\n",
      "release_date                       ...                                   \n",
      "1947-08-17          NaN       NaN  ...             NaN             NaN   \n",
      "1947-08-18          NaN       NaN  ...             NaN             NaN   \n",
      "1947-08-19          NaN       NaN  ...             NaN             NaN   \n",
      "1947-08-20          NaN       NaN  ...             NaN             NaN   \n",
      "1947-08-21          NaN       NaN  ...             NaN             NaN   \n",
      "\n",
      "                GCEC1 FGCEC1 SLCEC1 CSUSHPISA SPCS20RSA HOUST HSN1F PERMIT  \n",
      "release_date                                                                \n",
      "1947-08-17    560.034      .      .       NaN       NaN   NaN   NaN    NaN  \n",
      "1947-08-18        NaN    NaN    NaN       NaN       NaN   NaN   NaN    NaN  \n",
      "1947-08-19        NaN    NaN    NaN       NaN       NaN   NaN   NaN    NaN  \n",
      "1947-08-20        NaN    NaN    NaN       NaN       NaN   NaN   NaN    NaN  \n",
      "1947-08-21        NaN    NaN    NaN       NaN       NaN   NaN   NaN    NaN  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "\n",
      "Skipped keys:\n",
      "USAUCSFRCONDOSMSAMID: No metadata\n",
      "PCEPI: No metadata\n",
      "CPIAUCSL: No metadata\n",
      "PPIACO: No metadata\n",
      "UNRATE: No metadata\n",
      "PAYEMS: No metadata\n",
      "JTSJOL: No metadata\n",
      "LMJVTTUVUSM647S: No metadata\n",
      "CES0500000003: No metadata\n",
      "STLFSI3: No metadata\n",
      "FRBKCLMCILA: No metadata\n",
      "CIVPART: No metadata\n",
      "INDPRO: No metadata\n",
      "IPFPNSS: No metadata\n",
      "IPCONGD: No metadata\n",
      "IPFUELS: No metadata\n",
      "DGORDER: No metadata\n",
      "ACOGNO: No metadata\n",
      "TTLCONS: No metadata\n",
      "ISRATIO: No metadata\n",
      "TCU: No metadata\n",
      "EFFR: No metadata\n",
      "MORTGAGE30US: No metadata\n",
      "DAAA: No metadata\n",
      "DBAA: No metadata\n",
      "TOTALSA: No metadata\n",
      "RSAFS: No metadata\n",
      "CSCICP03USM665S: No metadata\n",
      "CEFDISA066MSFRBNY: No metadata\n",
      "BACTSAMFRBDAL: No metadata\n",
      "CEFDFSA066MSFRBPHI: No metadata\n",
      "CBBTCUSD: No metadata\n",
      "DCOILWTICO: No metadata\n"
     ]
    }
   ],
   "source": [
    "meta_dict = {}\n",
    "data_dict = {}\n",
    "skipped_keys = []\n",
    "\n",
    "for source_key in fred_keys:\n",
    "    print(f\"Processing {source_key}...\")\n",
    "    try:\n",
    "        # 메타데이터 수집\n",
    "        meta_url = f'{BASE_URL}/series'\n",
    "        meta_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "        meta_r = requests.get(meta_url, params=meta_params).json().get('seriess', [])\n",
    "        if not meta_r:\n",
    "            print(f\"skip {source_key}: No metadata available\")\n",
    "            skipped_keys.append((source_key, \"No metadata\"))\n",
    "            continue\n",
    "        meta_df = pd.DataFrame(meta_r)\n",
    "        meta_dict[source_key] = meta_df\n",
    "\n",
    "        # release id\n",
    "        release_url = f'{BASE_URL}/series/release'\n",
    "        release_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "        release_response = requests.get(release_url, params=release_params).json()\n",
    "        if 'releases' not in release_response or not release_response['releases']:\n",
    "            print(f\"skip {source_key}: No release info\")\n",
    "            skipped_keys.append((source_key, \"No release info\"))\n",
    "            continue\n",
    "        release_id = release_response['releases'][0]['id']\n",
    "\n",
    "        # obs\n",
    "        obs_url = f'{BASE_URL}/series/observations'\n",
    "        obs_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "        obs_response = requests.get(obs_url, params=obs_params).json()\n",
    "        if 'observations' not in obs_response:\n",
    "            print(f\"skip {source_key}: No observations\")\n",
    "            skipped_keys.append((source_key, \"No observations\"))\n",
    "            continue\n",
    "        obs_data = obs_response['observations']\n",
    "        if not obs_data:\n",
    "            print(f\"skip {source_key}: Empty observations\")\n",
    "            skipped_keys.append((source_key, \"Empty observations\"))\n",
    "            continue\n",
    "\n",
    "        # release dates\n",
    "        rel_url = f'{BASE_URL}/release/dates'\n",
    "        rel_params = {'api_key': API_KEY, 'file_type': 'json', 'release_id': release_id}\n",
    "        rel_data = requests.get(rel_url, params=rel_params).json()['release_dates']\n",
    "        if not rel_data:\n",
    "            print(f\"skip {source_key}: No release dates\")\n",
    "            skipped_keys.append((source_key, \"No release dates\"))\n",
    "            continue\n",
    "\n",
    "        # obs_df\n",
    "        obs_df = pd.DataFrame(obs_data)\n",
    "        obs_df['date'] = pd.to_datetime(obs_df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "        obs_df['base'] = (obs_df['date'] + pd.DateOffset(months=1)).dt.to_period('M').astype(str)\n",
    "        obs_df[source_key] = obs_df['value']\n",
    "        obs_df = obs_df[['base', source_key]]\n",
    "\n",
    "        # release_df\n",
    "        rel_df = pd.DataFrame(rel_data)\n",
    "        rel_df['release_date'] = pd.to_datetime(rel_df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "        rel_df['base'] = rel_df['release_date'].dt.to_period('M').astype(str)\n",
    "        rel_df = rel_df[['release_date', 'base']]\n",
    "\n",
    "        # merge + 중복 제거 + 리샘플링\n",
    "        temp_df = obs_df.merge(rel_df, on='base', how='left')  # inner 대신 left로 변경\n",
    "        temp_df = temp_df.drop(columns=['base']).set_index('release_date')\n",
    "        temp_df = temp_df.groupby('release_date').first()  # 중복 제거\n",
    "        temp_df = temp_df.resample('D').asfreq()\n",
    "\n",
    "        data_dict[source_key] = temp_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"skip {source_key}: {e}\")\n",
    "        skipped_keys.append((source_key, str(e)))\n",
    "        continue\n",
    "\n",
    "# 데이터 병합\n",
    "merged_df = pd.concat(data_dict.values(), axis=1, join='outer')\n",
    "meta_full_df = pd.concat(meta_dict.values(), axis=0, ignore_index=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"메타데이터 df shape:\", meta_full_df.shape)\n",
    "print(\"merged_df shape:\", merged_df.shape)\n",
    "print(meta_full_df.head())\n",
    "print(merged_df.head())\n",
    "print(\"\\nSkipped keys:\")\n",
    "for key, reason in skipped_keys:\n",
    "    print(f\"{key}: {reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "{'realtime_start': '2025-03-19', 'realtime_end': '2025-03-19', 'seriess': [{'id': 'DCOILWTICO', 'realtime_start': '2025-03-19', 'realtime_end': '2025-03-19', 'title': 'Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma', 'observation_start': '1986-01-02', 'observation_end': '2025-03-10', 'frequency': 'Daily', 'frequency_short': 'D', 'units': 'Dollars per Barrel', 'units_short': '$ per Barrel', 'seasonal_adjustment': 'Not Seasonally Adjusted', 'seasonal_adjustment_short': 'NSA', 'last_updated': '2025-03-12 12:10:03-05', 'popularity': 77, 'notes': 'Definitions, Sources and Explanatory Notes (http://www.eia.doe.gov/dnav/pet/TblDefs/pet_pri_spt_tbldef2.asp)'}]}\n"
     ]
    }
   ],
   "source": [
    "source_key = \"DCOILWTICO\"\n",
    "meta_url = f'{BASE_URL}/series'\n",
    "meta_params = {'api_key': API_KEY, 'file_type': 'json', 'series_id': source_key}\n",
    "response = requests.get(meta_url, params=meta_params)\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import yfinance as yf\n",
    "\n",
    "API_KEY = 'e3e226dad48bd746bbe401b9e1d4de13'\n",
    "BASE_URL = 'https://api.stlouisfed.org/fred'\n",
    "\n",
    "source_keys = pd.read_csv('../data/nowcast-variables.csv')\n",
    "fred_keys = source_keys[source_keys['hist_source'] == 'fred']['hist_source_key']\n",
    "yf_tickers = source_keys[source_keys['hist_source'] == 'yahoo']['hist_source_key']\n",
    "\n",
    "def fetch_yahoo_data(tickers, start='2000-01-01', end='2024-12-31'):\n",
    "    data_dict = {}\n",
    "    for ticker in tickers:\n",
    "        print(f\"Fetching Yahoo data for {ticker}...\")\n",
    "        data = yf.download(ticker, start=start, end=end)\n",
    "        data = data['Close']\n",
    "        data.name = ticker\n",
    "        data_dict[ticker] = data\n",
    "    market_df = pd.concat(data_dict.values(), axis=1)\n",
    "    market_df.columns = data_dict.keys()\n",
    "    market_df.index.name = 'Date'\n",
    "    return market_df\n",
    "\n",
    "def fetch_fred_series(source_key, api_key, base_url, timeout=10):\n",
    "    try:\n",
    "        # 메타데이터\n",
    "        meta_url = f'{base_url}/series'\n",
    "        meta_params = {'api_key': api_key, 'file_type': 'json', 'series_id': source_key}\n",
    "        meta_response = requests.get(meta_url, params=meta_params, timeout=timeout)\n",
    "        meta_json = meta_response.json()\n",
    "        meta_r = meta_json.get('seriess', [])\n",
    "        if not meta_r:\n",
    "            return None, None, f\"No metadata available - Response: {meta_json}\"\n",
    "\n",
    "        meta_df = pd.DataFrame(meta_r)\n",
    "        frequency = meta_df['frequency_short'].iloc[0]  # 주기: D, W, M, Q 등\n",
    "\n",
    "        release_url = f'{base_url}/series/release'\n",
    "        release_params = {'api_key': api_key, 'file_type': 'json', 'series_id': source_key}\n",
    "        release_response = requests.get(release_url, params=release_params, timeout=timeout)\n",
    "        release_json = release_response.json()\n",
    "        if 'releases' not in release_json or not release_json['releases']:\n",
    "            return None, None, \"No release info\"\n",
    "        release_id = release_json['releases'][0]['id']\n",
    "\n",
    "        obs_url = f'{base_url}/series/observations'\n",
    "        obs_params = {'api_key': api_key, 'file_type': 'json', 'series_id': source_key}\n",
    "        obs_response = requests.get(obs_url, params=obs_params, timeout=timeout)\n",
    "        obs_json = obs_response.json()\n",
    "        if 'observations' not in obs_json or not obs_json['observations']:\n",
    "            return None, None, \"No observations or empty\"\n",
    "\n",
    "        obs_df = pd.DataFrame(obs_json['observations'])\n",
    "        obs_df['date'] = pd.to_datetime(obs_df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "        obs_df[source_key] = obs_df['value']\n",
    "\n",
    "        # 주기에 따라 날짜 조정\n",
    "        if frequency == 'M':  # 월간\n",
    "            obs_df['adjusted_date'] = obs_df['date'] + pd.offsets.MonthEnd(0) + pd.offsets.MonthBegin(1)\n",
    "        elif frequency == 'Q':  # 분기\n",
    "            obs_df['adjusted_date'] = obs_df['date'] + pd.offsets.QuarterEnd(0) + pd.offsets.MonthBegin(2)  # 2개월 뒤\n",
    "        elif frequency == 'W':  # 주간\n",
    "            obs_df['adjusted_date'] = obs_df['date'] + pd.offsets.Week(1)  # 1주 뒤\n",
    "        else:\n",
    "            obs_df['adjusted_date'] = obs_df['date']  # 기타 주기\n",
    "\n",
    "        obs_df = obs_df[['adjusted_date', source_key]].set_index('adjusted_date')\n",
    "\n",
    "        rel_url = f'{base_url}/release/dates'\n",
    "        rel_params = {'api_key': api_key, 'file_type': 'json', 'release_id': release_id}\n",
    "        rel_response = requests.get(rel_url, params=rel_params, timeout=timeout)\n",
    "        rel_data = rel_response.json()['release_dates']\n",
    "        if not rel_data:\n",
    "            return None, None, \"No release dates\"\n",
    "\n",
    "        rel_df = pd.DataFrame(rel_data)\n",
    "        rel_df['release_date'] = pd.to_datetime(rel_df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "        rel_df = rel_df[['release_date']].sort_values('release_date')\n",
    "\n",
    "        temp_df = obs_df.reset_index()\n",
    "        temp_df = pd.merge_asof(temp_df, rel_df, left_on='adjusted_date', right_on='release_date', direction='forward')\n",
    "        temp_df = temp_df.drop(columns=['adjusted_date'])\n",
    "        temp_df = temp_df.groupby('release_date').first()\n",
    "        temp_df = temp_df.resample('D').asfreq()\n",
    "\n",
    "        return meta_df, temp_df, None\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, None, str(e)\n",
    "\n",
    "def fetch_fred_data(keys, api_key, base_url, delay_seconds=0.3):\n",
    "    meta_dict = {}\n",
    "    data_dict = {}\n",
    "    skipped_keys = []\n",
    "\n",
    "    for source_key in keys:\n",
    "        print(f\"Processing {source_key}...\")\n",
    "        meta_df, series_df, error = fetch_fred_series(source_key, api_key, base_url)\n",
    "        if error:\n",
    "            print(f\"skip {source_key}: {error}\")\n",
    "            skipped_keys.append((source_key, error))\n",
    "        else:\n",
    "            meta_dict[source_key] = meta_df\n",
    "            data_dict[source_key] = series_df\n",
    "        time.sleep(delay_seconds)\n",
    "\n",
    "    return meta_dict, data_dict, skipped_keys\n",
    "\n",
    "# 실행\n",
    "market_df = fetch_yahoo_data(yf_tickers)\n",
    "\n",
    "mid_point = len(fred_keys) // 2\n",
    "first_half = fred_keys[:mid_point]\n",
    "second_half = fred_keys[mid_point:]\n",
    "\n",
    "print(\"Fetching first half of FRED keys...\")\n",
    "meta_dict1, data_dict1, skipped1 = fetch_fred_data(first_half, API_KEY, BASE_URL)\n",
    "\n",
    "print(\"Waiting before second half...\")\n",
    "time.sleep(60)\n",
    "\n",
    "print(\"Fetching second half of FRED keys...\")\n",
    "meta_dict2, data_dict2, skipped2 = fetch_fred_data(second_half, API_KEY, BASE_URL)\n",
    "\n",
    "meta_dict = {**meta_dict1, **meta_dict2}\n",
    "data_dict = {**data_dict1, **data_dict2}\n",
    "skipped_keys = skipped1 + skipped2\n",
    "\n",
    "fred_merged_df = pd.concat(data_dict.values(), axis=1, join='outer')\n",
    "fred_meta_full_df = pd.concat(meta_dict.values(), axis=0, ignore_index=True)\n",
    "final_df = pd.concat([market_df, fred_merged_df], axis=1)\n",
    "\n",
    "print(\"FRED 메타데이터 df shape:\", fred_meta_full_df.shape)\n",
    "print(\"FRED merged_df shape:\", fred_merged_df.shape)\n",
    "print(\"Market df shape:\", market_df.shape)\n",
    "print(\"Final df shape:\", final_df.shape)\n",
    "print(fred_meta_full_df.head())\n",
    "print(final_df.head())\n",
    "print(\"\\nSkipped keys:\")\n",
    "for key, reason in skipped_keys:\n",
    "    print(f\"{key}: {reason}\")\n",
    "\n",
    "# 주기별 데이터 확인\n",
    "print(\"\\nCPIAUCSL (월간):\")\n",
    "print(final_df[final_df['CPIAUCSL'].notna()][['CPIAUCSL']])\n",
    "print(\"\\nGASREGW (주간):\")\n",
    "print(final_df[final_df['GASREGW'].notna()][['GASREGW']])\n",
    "print(\"\\nGDPC1 (분기, 예시):\")\n",
    "print(final_df[final_df['GDPC1'].notna()][['GDPC1']] if 'GDPC1' in final_df.columns else \"GDPC1 not in data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching additional FRED keys...\n",
      "Processing additional key GASREGW...\n"
     ]
    }
   ],
   "source": [
    "# 추가 키 다운로드 및 병합\n",
    "additional_keys = ['GASREGW']  # 추가로 다운로드할 키 목록\n",
    "print(\"\\nFetching additional FRED keys...\")\n",
    "additional_meta_dict = {}\n",
    "additional_data_dict = {}\n",
    "additional_skipped = []\n",
    "\n",
    "for key in additional_keys:\n",
    "    print(f\"Processing additional key {key}...\")\n",
    "    meta_df, series_df, error = fetch_fred_series(key, API_KEY, BASE_URL)\n",
    "    if error:\n",
    "        print(f\"skip {key}: {error}\")\n",
    "        additional_skipped.append((key, error))\n",
    "    else:\n",
    "        additional_meta_dict[key] = meta_df\n",
    "        additional_data_dict[key] = series_df\n",
    "    time.sleep(1)  # 추가 요청 간 딜레이\n",
    "\n",
    "# 기존 데이터에 병합\n",
    "if additional_data_dict:\n",
    "    additional_df = pd.concat(additional_data_dict.values(), axis=1, join='outer')\n",
    "    final_df = pd.concat([final_df, additional_df], axis=1)\n",
    "\n",
    "if additional_meta_dict:\n",
    "    additional_meta_df = pd.concat(additional_meta_dict.values(), axis=0, ignore_index=True)\n",
    "    fred_meta_full_df = pd.concat([fred_meta_full_df, additional_meta_df], axis=0, ignore_index=True)\n",
    "\n",
    "skipped_keys.extend(additional_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           GASREGW\n",
      "2009-09-28   1.191\n",
      "2009-10-05   2.499\n",
      "2009-10-12   2.468\n",
      "2009-10-19   2.489\n",
      "2009-10-26   2.574\n",
      "...            ...\n",
      "2025-02-18   3.128\n",
      "2025-02-24   3.148\n",
      "2025-03-03   3.125\n",
      "2025-03-10   3.078\n",
      "2025-03-17   3.069\n",
      "\n",
      "[806 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_df[final_df['GASREGW'].notna()][['GASREGW']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../data/final_df.csv')\n",
    "fred_meta_full_df.to_csv('../data/fred_meta_full_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 거시경제 지표의 메타 정보를 인기 순으로 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id                                              title  \\\n",
      "0                T10Y2Y  10-Year Treasury Constant Maturity Minus 2-Yea...   \n",
      "1              FEDFUNDS                       Federal Funds Effective Rate   \n",
      "2              CPIAUCSL  Consumer Price Index for All Urban Consumers: ...   \n",
      "3                UNRATE                                  Unemployment Rate   \n",
      "4                T10Y3M  10-Year Treasury Constant Maturity Minus 3-Mon...   \n",
      "...                 ...                                                ...   \n",
      "5275  BOGZ1FL263061145Q  Rest of the World; Treasury Securities Held by...   \n",
      "5276  BOGZ1LM503062003Q  Other Financial Business; Municipal Securities...   \n",
      "5277           FFWSJLOW  Low Value of the Federal Funds Rate for the In...   \n",
      "5278            FFHTLOW  Low Value of the Federal Funds Rate for the In...   \n",
      "5279             WUIBRA                 World Uncertainty Index for Brazil   \n",
      "\n",
      "      popularity  \n",
      "0            100  \n",
      "1             98  \n",
      "2             95  \n",
      "3             95  \n",
      "4             94  \n",
      "...          ...  \n",
      "5275          10  \n",
      "5276          10  \n",
      "5277          10  \n",
      "5278          10  \n",
      "5279          10  \n",
      "\n",
      "[5280 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: 모든 소스 가져오기\n",
    "source_url = f'{BASE_URL}/sources'\n",
    "source_params = {'api_key': API_KEY, 'file_type': 'json'}\n",
    "sources = requests.get(source_url, params=source_params).json()['sources']\n",
    "source_ids = [s['id'] for s in sources]\n",
    "\n",
    "all_meta = []\n",
    "\n",
    "# Step 2: 소스별 시리즈 수집\n",
    "for sid in source_ids:\n",
    "    series_url = f'{BASE_URL}/source/releases'\n",
    "    series_params = {\n",
    "        'api_key': API_KEY,\n",
    "        'file_type': 'json',\n",
    "        'source_id': sid\n",
    "    }\n",
    "    releases = requests.get(series_url, params=series_params).json().get('releases', [])\n",
    "    for release in releases:\n",
    "        rel_id = release['id']\n",
    "        series_fetch_url = f'{BASE_URL}/release/series'\n",
    "        series_fetch_params = {\n",
    "            'api_key': API_KEY,\n",
    "            'file_type': 'json',\n",
    "            'release_id': rel_id,\n",
    "            'order_by': 'popularity',\n",
    "            'sort_order': 'desc',\n",
    "            'limit': 1000\n",
    "        }\n",
    "        series_data = requests.get(series_fetch_url, params=series_fetch_params).json()\n",
    "        all_meta.extend(series_data.get('seriess', []))\n",
    "\n",
    "# Step 3: DataFrame 변환 및 필터링\n",
    "meta_df = pd.DataFrame(all_meta)\n",
    "meta_df = meta_df.drop_duplicates(subset=['id'])\n",
    "meta_df = meta_df[meta_df['popularity'] >= 10].sort_values('popularity', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(meta_df[['id', 'title', 'popularity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
